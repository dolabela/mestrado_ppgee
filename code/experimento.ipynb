{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experimento Final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmd2Y-L2bntB",
        "outputId": "dad77d11-e4a0-4009-b49b-e1de094d47e2"
      },
      "source": [
        "!pip uninstall pyfts -y\n",
        "!pip install git+https://github.com/PYFTS/pyFTS\n",
        "!pip install SimpSOM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping pyfts as it is not installed.\u001b[0m\n",
            "Collecting git+https://github.com/PYFTS/pyFTS\n",
            "  Cloning https://github.com/PYFTS/pyFTS to /tmp/pip-req-build-dgbu3c0t\n",
            "  Running command git clone -q https://github.com/PYFTS/pyFTS /tmp/pip-req-build-dgbu3c0t\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyFTS==1.6) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyFTS==1.6) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyFTS==1.6) (1.1.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyFTS==1.6) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyFTS==1.6) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyFTS==1.6) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyFTS==1.6) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyFTS==1.6) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->pyFTS==1.6) (1.15.0)\n",
            "Building wheels for collected packages: pyFTS\n",
            "  Building wheel for pyFTS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyFTS: filename=pyFTS-1.6-cp37-none-any.whl size=217117 sha256=eda9d77820d5730f5ef36a3db106c9044f0014e8debc08e2ecc545ff835bec78\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6oa7twt3/wheels/e7/32/a9/230470113df5a73242a5a6d05671cb646db97abf14bbce2644\n",
            "Successfully built pyFTS\n",
            "Installing collected packages: pyFTS\n",
            "Successfully installed pyFTS-1.6\n",
            "Collecting SimpSOM\n",
            "  Downloading https://files.pythonhosted.org/packages/74/93/a7db1b983074ef08c40b70ae333c4804de1e34c74ad74a307d40cb62d932/SimpSOM-1.3.4.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from SimpSOM) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from SimpSOM) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from SimpSOM) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SimpSOM) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SimpSOM) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SimpSOM) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SimpSOM) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->SimpSOM) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->SimpSOM) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->SimpSOM) (1.15.0)\n",
            "Building wheels for collected packages: SimpSOM\n",
            "  Building wheel for SimpSOM (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SimpSOM: filename=SimpSOM-1.3.4-cp37-none-any.whl size=17088 sha256=4ca1fb942b424add9cdbe39079a2116f09813ca29d7f6fb15274f9729f59ae3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/76/ee/c02f0bc20af4cd8f46ee4142ebf7bb654b737d6d8f2360d26b\n",
            "Successfully built SimpSOM\n",
            "Installing collected packages: SimpSOM\n",
            "Successfully installed SimpSOM-1.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkoRZnEIwHW2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyFTS.partitioners import Grid\n",
        "from pyFTS.models import hofts, pwfts\n",
        "from pyFTS.common import Util as cUtil\n",
        "from pyFTS.benchmarks import Measures\n",
        "from pyFTS.common.transformations.differential import Differential "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AcO3WlwTgou"
      },
      "source": [
        "## NADAQ e S&P500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMEo4j7AqLTN",
        "outputId": "541c38e4-6f50-4eb1-eea3-bbb900524496"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "closing_prices = pd.read_csv('/content/drive/MyDrive/meu_mestrado/closing_price_nasdaq_sp500.csv', index_col = 0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqYn0U4HTJ-a",
        "outputId": "ae42139b-b417-45d8-f313-5b9f8229a7ed"
      },
      "source": [
        "closing_prices['sentiment_hesitant'] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2016-12-28    939\n",
              "2016-12-29    938\n",
              "2016-12-30    925\n",
              "2017-01-03    941\n",
              "2017-01-04    826\n",
              "             ... \n",
              "2020-05-22    753\n",
              "2020-05-26    800\n",
              "2020-05-27    818\n",
              "2020-05-28    775\n",
              "2020-05-29    749\n",
              "Name: sentiment_hesitant, Length: 860, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrsuiPLrP7gX",
        "outputId": "cbdc62fd-097a-468a-87bb-37b6dbd845ee"
      },
      "source": [
        "closing_prices['sp500_close_shift'] = closing_prices['sp500_close'].shift(1)\n",
        "\n",
        "closing_prices['nasdaq_close_shift'] = closing_prices['nasdaq_close'].shift(1)\n",
        "\n",
        "closing_prices['sp500_return_shift'] = closing_prices['sp500_return'].shift(1)\n",
        "\n",
        "closing_prices['nasdaq_return_shift'] = closing_prices['nasdaq_return'].shift(1)\n",
        "\n",
        "closing_prices['sentiment_hesitant_shift'] = closing_prices['sentiment_hesitant'].shift(1)\n",
        "\n",
        "closing_prices['sentiment_hesitant'] = closing_prices['sentiment_hesitant']\n",
        "\n",
        "nasdaq_mv = closing_prices[['nasdaq_close','hesitant_return','nasdaq_close_shift', 'sentiment_hesitant','sentiment_hesitant_shift']]\n",
        "sp500_mv = closing_prices[['sp500_close','hesitant_return','sp500_close_shift', 'sentiment_hesitant','sentiment_hesitant_shift']]\n",
        "\n",
        "nasdaq_mv.rename(columns = {'nasdaq_close_shift': 'close_shift'}, \n",
        "                 inplace=True)\n",
        "\n",
        "sp500_mv.rename(columns = {'sp500_close_shift': 'close_shift'}, \n",
        "                 inplace=True)\n",
        "\n",
        "nasdaq_mv.dropna(inplace=True)\n",
        "\n",
        "sp500_mv.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqmfSFyZEluU"
      },
      "source": [
        "from pyFTS.models.multivariate import variable, mvfts, wmvfts\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from statistics import mean \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyFTS.partitioners import Grid\n",
        "from pyFTS.models import hofts, pwfts, chen \n",
        "from pyFTS.common import Util as cUtil\n",
        "from pyFTS.benchmarks import Measures\n",
        "from pyFTS.common.transformations.differential import Differential \n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "# def check_direcao (row):\n",
        "#   if row['real'] >= 0 and row['forecast'] >= 0:\n",
        "#     return 1 \n",
        "#   elif row['real'] <= 0 and row['forecast'] <= 0:\n",
        "#     return 1 \n",
        "#   else:\n",
        "#     return 0\n",
        "\n",
        "def MDA(original, forecasts):\n",
        "   n = len(original)\n",
        "   count =0\n",
        "   for t in range(1,n):\n",
        "      # print(original[t], original[t-1])\n",
        "      # print(forecasts[t], forecasts[t-1])\n",
        "\n",
        "      y = 1 if float(original[t]) - float(original[t-1]) >= 0 else -1\n",
        "      f = 1 if float(forecasts [t]) - float(forecasts[t-1]) >=0 else -1\n",
        "      count += 1 if y == f else 0\n",
        "   return count/n\n",
        "\n",
        "# def rmse(targets, forecasts, order=0, offset=0):\n",
        "#     \"\"\"\n",
        "#     Root Mean Squared Error\n",
        "#     :param targets: array of targets\n",
        "#     :param forecasts: array of forecasts\n",
        "#     :param order: model order\n",
        "#     :param offset: forecast offset related to target. \n",
        "#     :return: \n",
        "#     \"\"\"\n",
        "#     if isinstance(targets, list):\n",
        "#         targets = np.array(targets)\n",
        "#     if isinstance(forecasts, list):\n",
        "#         forecasts = np.array(forecasts)\n",
        "    \n",
        "#     if offset == 0:\n",
        "#         return np.sqrt(np.nanmean((targets[order:] - forecasts[:]) ** 2))\n",
        "#     else:\n",
        "#         return np.sqrt(np.nanmean((targets[order+offset:] - forecasts[:-offset]) ** 2))\n",
        "\n",
        "\n",
        "# def mape(targets, forecasts):\n",
        "#     \"\"\"\n",
        "#     Mean Average Percentual Error\n",
        "#     :param targets: \n",
        "#     :param forecasts: \n",
        "#     :return: \n",
        "#     \"\"\"\n",
        "#     if isinstance(targets, list):\n",
        "#         targets = np.array(targets)\n",
        "#     if isinstance(forecasts, list):\n",
        "#         forecasts = np.array(forecasts)\n",
        "#     return np.nanmean(np.abs(np.divide(np.subtract(targets, forecasts), targets))) * 100\n",
        "\n",
        "\n",
        "def run_multivariate(time_series,variables, sent_n_part, close_n_part,window_size,train_test_split):\n",
        "  measurements = {'rmse':[], 'mape': [], 'u': [], 'nrmse1':[],'nrmse2':[] }\n",
        "  diff = Differential(1)\n",
        "  main_column = time_series.columns[0] \n",
        "  time_series = time_series[[main_column] + variables]\n",
        "  lista_forecast = []\n",
        "  lista_real = []\n",
        "  # print(time_series)\n",
        "  # print(main_column)\n",
        "  for count, train, test in cUtil.sliding_window(time_series, window_size, train_test_split, 1 - train_test_split):\n",
        "    # print('-1')\n",
        "    variable_list = []\n",
        "    for v in variables:\n",
        "      # print('passou nas variavel')\n",
        "      variable_list.append(variable.Variable(v, alias=v[0], npart=sent_n_part,\n",
        "                                        partitioner=Grid.GridPartitioner, data=train,\n",
        "                                        data_label=v))\n",
        "      \n",
        "\n",
        "    if is_diff:\n",
        "      # print('os_preco')\n",
        "      var_price = variable.Variable('Price', alias='P', npart=close_n_part,\n",
        "                                    partitioner=Grid.GridPartitioner, data=train,\n",
        "                                  transformation=diff,\n",
        "                                  data_label=str(main_column))\n",
        "      # print('ao o o')\n",
        "      \n",
        "    else:\n",
        "      var_price = variable.Variable('Price', alias='P', npart=close_n_part,\n",
        "                                      partitioner=Grid.GridPartitioner, data=train,\n",
        "                                      data_label=main_column)\n",
        "    # print([var_price] + variable_list)\n",
        "    # print(0)\n",
        "    # model = wmvfts.WeightedMVFTS(explanatory_variables=[var_price] + variable_list,\n",
        "    #                     target_variable=var_price)\n",
        "    model = mvfts.MVFTS(explanatory_variables=[var_price] + variable_list,\n",
        "                        target_variable=var_price)\n",
        "    model.fit(train)\n",
        "    # print('1')\n",
        "    # print('2')\n",
        "    forecast = deepcopy(model).predict(test)\n",
        "    rmse_t, mape_t, _ = deepcopy(Measures.get_point_statistics(test, deepcopy(model)))\n",
        "    # print('3')\n",
        "    measurements['rmse'].append( rmse_t)\n",
        "    measurements['mape'].append( mape_t)\n",
        "    # print('4')\n",
        "    lista_forecast = lista_forecast + list(forecast)\n",
        "    lista_real = lista_real + list(test[main_column])\n",
        "    # print('5')\n",
        "  # print(measurements['mape'], measurements['rmse'])\n",
        "  # print(lista_real, lista_forecast)\n",
        "  # print('6')\n",
        "  mda = MDA(lista_real, lista_forecast)\n",
        "  # print(mda)\n",
        "  rmse_t =  mean(measurements['rmse'])\n",
        "  mape_t = mean(measurements['mape'])\n",
        "  variables_t = '|'.join(variables)\n",
        "  # print('7')\n",
        "  df_final = pd.DataFrame([[close_n_part, sent_n_part, main_column, window_size, mda,rmse_t, mape_t, variables_t]], columns = ['close_n_part', 'sent_n_part', 'index', 'window_size', 'accuracy', 'rmse', 'mape', 'variables'])\n",
        "  return df_final\n",
        "\n",
        "def run_univariate(df,n_part,window_size,train_test_split):\n",
        "  measurements = {'rmse':[], 'mape': [], 'u': [], 'nrmse1':[],'nrmse2':[] }\n",
        "  diff = Differential(1)\n",
        "  time_series = df.iloc[:,0].values\n",
        "  index = df.columns[0]\n",
        "  acertos = []\n",
        "  lista_forecast = []\n",
        "  lista_real = []\n",
        "  for count, train, test in cUtil.sliding_window(time_series, window_size, train_test_split, 1 - train_test_split):\n",
        "    if is_diff:\n",
        "      fs = Grid.GridPartitioner(data=train, npart=n_part, transformation=diff)\n",
        "    else:\n",
        "      fs = Grid.GridPartitioner(data=train, npart=n_part)\n",
        "    model = chen.ConventionalFTS(partitioner=fs)\n",
        "    # model = hofts.WeightedHighOrderFTS(partitioner=fs, order=1)\n",
        "    if is_diff:\n",
        "      model.append_transformation(diff)\n",
        "\n",
        "    model.fit(train)\n",
        "    forecast = model.predict(test)\n",
        "    rmse_t, mape_t, _ = Measures.get_point_statistics(test, model)\n",
        "    measurements['rmse'].append( rmse_t)\n",
        "    measurements['mape'].append( mape_t)\n",
        "    lista_forecast = lista_forecast + list(forecast)\n",
        "    lista_real = lista_real + list(test[1:])\n",
        "  # print(lista_forecast)\n",
        "  # print(lista_real)\n",
        "  mda = MDA(lista_real, lista_forecast)\n",
        "  rmse_t =  mean(measurements['rmse'])\n",
        "  mape_t = mean(measurements['mape'])\n",
        "  df_final = pd.DataFrame([[close_n_part, '-', index, window_size, mda,rmse_t, mape_t, '-']], columns = ['close_n_part', 'sent_n_part', 'index', 'window_size', 'accuracy', 'rmse', 'mape', 'variables'])\n",
        "  return df_final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1sMcJFUWEE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VumNy5_EtD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a440a06-6056-4f33-95f6-5a9d772f84fa"
      },
      "source": [
        "\n",
        "close_n_part_list = [5, 10, 15,20,25]\n",
        "sent_n_part_list = [3, 5, 7]\n",
        "is_diff = 1\n",
        "window_size_list = [600]\n",
        "ts_list = [nasdaq_mv, sp500_mv]\n",
        "train_test_split = 0.95\n",
        "df = pd.DataFrame()\n",
        "variable_list = [ ['sentiment_hesitant']]\n",
        "\n",
        "\n",
        "for close_n_part in close_n_part_list:\n",
        "  for window_size in window_size_list:\n",
        "    for ts in ts_list:\n",
        "\n",
        "      df_aux = run_univariate(ts,close_n_part,window_size,train_test_split)\n",
        "      df = pd.concat([df, df_aux])\n",
        "\n",
        "      for sent_n_part in sent_n_part_list:\n",
        "        print(close_n_part,window_size, sent_n_part)\n",
        "        for variables in variable_list:\n",
        "\n",
        "          df_aux = run_multivariate(ts,variables, sent_n_part, close_n_part,window_size,train_test_split)\n",
        "\n",
        "          df = pd.concat([df, df_aux])\n",
        "# run_univariate(sp500_mv, close_n_part,window_size,train_test_split)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 600 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyFTS/models/multivariate/mvfts.py:165: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret.append(np.dot(mv,mp.T)/np.nansum(mv))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 600 5\n",
            "5 600 7\n",
            "5 600 3\n",
            "5 600 5\n",
            "5 600 7\n",
            "10 600 3\n",
            "10 600 5\n",
            "10 600 7\n",
            "10 600 3\n",
            "10 600 5\n",
            "10 600 7\n",
            "15 600 3\n",
            "15 600 5\n",
            "15 600 7\n",
            "15 600 3\n",
            "15 600 5\n",
            "15 600 7\n",
            "20 600 3\n",
            "20 600 5\n",
            "20 600 7\n",
            "20 600 3\n",
            "20 600 5\n",
            "20 600 7\n",
            "25 600 3\n",
            "25 600 5\n",
            "25 600 7\n",
            "25 600 3\n",
            "25 600 5\n",
            "25 600 7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}